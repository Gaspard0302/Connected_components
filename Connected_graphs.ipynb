{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course project - Database Management MAP543\n",
    "***\n",
    "In the following, we explore an efficient and scalable approach in MapReduce to find all the connected components in a given graph. Finding connected components in a graph is a well-known problem in a wide variety of application areas such as social network analysis, data mining, image processing ...\n",
    "\n",
    "•The algorithm is descibed in this [paper](https://www.cse.unr.edu/~hkardes/pdfs/ccf.pdf)\n",
    "\n",
    "•The work to consists of understanding the MapReduce algorithm, and coding it into Spark by using both RDD and DataFrames \n",
    "\n",
    "•Both Python and Scala implementations must be provided,  \n",
    "\n",
    "•Experimental analysis comparing the RDD and DataFrame versions has to be conducted on graphs of increasing size \n",
    "\n",
    "•For small graphs use Databricks, for bigger ones (<20GB) use the GC cluster.\n",
    "\n",
    "\n",
    "We will also implement different techniques and compare them, based ont this [video](https://www.youtube.com/watch?v=Io1x6mQlh1E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Couldn't find Spark, make sure SPARK_HOME env is set or Spark is in an expected location (e.g. from homebrew installation).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfindspark\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m findspark\u001b[38;5;241m.\u001b[39minit()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/findspark.py:143\u001b[0m, in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make pyspark importable.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mSets environment variables and adds dependencies to sys.path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    configure and import pyspark.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m spark_home:\n\u001b[0;32m--> 143\u001b[0m     spark_home \u001b[38;5;241m=\u001b[39m find()\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m python_path:\n\u001b[1;32m    146\u001b[0m     python_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYSPARK_PYTHON\u001b[39m\u001b[38;5;124m\"\u001b[39m, sys\u001b[38;5;241m.\u001b[39mexecutable)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/findspark.py:46\u001b[0m, in \u001b[0;36mfind\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         spark_home \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(pyspark\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m spark_home:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find Spark, make sure SPARK_HOME env is set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or Spark is in an expected location (e.g. from homebrew installation).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spark_home\n",
      "\u001b[0;31mValueError\u001b[0m: Couldn't find Spark, make sure SPARK_HOME env is set or Spark is in an expected location (e.g. from homebrew installation)."
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph is a mathematical structure used to model relationships between objects. It consists of a set of nodes and a set of edges that connect pairs of nodes.\n",
    "\n",
    "A graph is said to be connected if for every pair of vertices in a graph, there exists a sequence of edges that forms a path between those vertices.\n",
    "\n",
    "We chose to use the [Web Google graph](http://snap.stanford.edu/data/web-Google.html) released in 2002 by Google. There are 875K nodes and 5.1M edges in this graph. Nodes represent web pages and directed edges represent hyperlinks between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"./web-Google.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
